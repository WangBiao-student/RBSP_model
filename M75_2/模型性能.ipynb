{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "# 完全忽略PerformanceWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df=pd.read_hdf('combined_df_train.h5', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Interpolated_Lstar          Flux\n",
      "0                  1.1      9.418266\n",
      "1                  1.2   1303.344361\n",
      "2                  1.3   7924.691321\n",
      "3                  1.4  17801.389684\n",
      "4                  1.5  25389.433811\n",
      "5                  1.6  27976.041502\n",
      "6                  1.7  27670.045493\n",
      "7                  1.8  27407.757962\n",
      "8                  1.9  25667.662688\n",
      "9                  2.0  22366.886339\n",
      "10                 2.1  19164.690013\n",
      "11                 2.2  14793.460049\n",
      "12                 2.3  10905.208116\n",
      "13                 2.4   7548.586435\n",
      "14                 2.5   5141.551134\n",
      "15                 2.6   3259.051810\n",
      "16                 2.7   2317.415383\n",
      "17                 2.8   1498.324184\n",
      "18                 2.9   1137.266388\n",
      "19                 3.0    884.807613\n",
      "20                 3.1    802.545429\n",
      "21                 3.2    822.405704\n",
      "22                 3.3    795.809448\n",
      "23                 3.4    923.007798\n",
      "24                 3.5   1035.356267\n",
      "25                 3.6   1235.437768\n",
      "26                 3.7   1413.202965\n",
      "27                 3.8   1599.134476\n",
      "28                 3.9   1823.142395\n",
      "29                 4.0   2097.068962\n",
      "30                 4.1   2286.391227\n",
      "31                 4.2   2585.695892\n",
      "32                 4.3   2775.524592\n",
      "33                 4.4   2943.402151\n",
      "34                 4.5   3100.229979\n",
      "35                 4.6   3207.537228\n",
      "36                 4.7   3353.135175\n",
      "37                 4.8   3420.327953\n",
      "38                 4.9   3461.510596\n",
      "39                 5.0   3474.994831\n",
      "40                 5.1   3436.358002\n",
      "41                 5.2   3249.930584\n",
      "42                 5.3   3061.141817\n",
      "43                 5.4   2980.737268\n",
      "44                 5.5   2775.228226\n",
      "45                 5.6   2490.745666\n",
      "46                 5.7   2230.845288\n",
      "47                 5.8   1931.902472\n",
      "48                 5.9   1592.121358\n",
      "49                 6.0   1387.689525\n",
      "50                 6.1   1422.058733\n",
      "51                 6.2   1314.426522\n",
      "52                 6.3   1557.412051\n",
      "53                 6.4   1176.433308\n",
      "54                 6.5           NaN\n"
     ]
    }
   ],
   "source": [
    "combined_df=combined_df[combined_df['Kp_0h'] <30]\n",
    "flux_dict = {}\n",
    "for i in np.arange(1.1, 6.6, 0.1):\n",
    "    combined_df_i = combined_df[combined_df['Interpolated_Lstar'] > i]\n",
    "    combined_df_i = combined_df_i[combined_df_i['Interpolated_Lstar'] < i + 0.1]\n",
    "    #计算范围内的Flux均值\n",
    "    flux_mean = combined_df_i['Flux'].mean()\n",
    "    #将均值存入字典中\n",
    "    flux_dict[i] = flux_mean\n",
    "#将flux_dict保存为csv文件\n",
    "flux_df = pd.DataFrame(list(flux_dict.items()), columns=['Interpolated_Lstar', 'Flux'])\n",
    "print(flux_df)\n",
    "flux_df.to_csv('flux_L_80.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=300\n",
    "VX_time1 = [f'VX_{i}h' for i in range(0, time_steps + 1)]\n",
    "SYMH_time2 = [f'SYMH_{i}h' for i in range(0, time_steps + 1)]\n",
    "VX_IS1_time3 = [f'VX_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_time4 = [f'BZGSM_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_time5 = [f'TEMP_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_time6 = [f'PDYN_{i}h' for i in range(0, time_steps + 1)]\n",
    "Kp_time7 = [f'Kp_{i}h' for i in range(0, time_steps + 1)]\n",
    "Dst_time8 = [f'Dst_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_time9 = [f'F107_{i}h' for i in range(0, time_steps + 1)]\n",
    "AE_time10 = [f'AE_{i}h' for i in range(0, time_steps + 1)]\n",
    "AL_time11 = [f'AL_{i}h' for i in range(0, time_steps + 1)]\n",
    "AU_time12 = [f'AU_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_IS1_time13 = [f'BZGSM_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_IS1_time14 = [f'TEMP_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_IS1_time15 = [f'PDYN_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_IS1_time16 = [f'F107_IS1_{i}h' for i in range(0, time_steps + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1202577, 151, 12)\n"
     ]
    }
   ],
   "source": [
    "X_time1 = combined_df[VX_time1].values  \n",
    "X_time2 = combined_df[SYMH_time2].values \n",
    "X_time3 = combined_df[VX_IS1_time3].values\n",
    "X_time4 = combined_df[BZGSM_time4].values\n",
    "X_time5 = combined_df[TEMP_time5].values\n",
    "X_time6 = combined_df[PDYN_time6].values\n",
    "X_time7 = combined_df[Kp_time7].values\n",
    "X_time8 = combined_df[Dst_time8].values\n",
    "X_time9 = combined_df[F107_time9].values\n",
    "X_time10 = combined_df[AE_time10].values\n",
    "X_time11 = combined_df[AL_time11].values\n",
    "X_time12 = combined_df[AU_time12].values\n",
    "X_time13 = combined_df[BZGSM_IS1_time13].values\n",
    "X_time14 = combined_df[TEMP_IS1_time14].values\n",
    "X_time15 = combined_df[PDYN_IS1_time15].values\n",
    "X_time16 = combined_df[F107_IS1_time16].values\n",
    "\n",
    "\n",
    "X_time = np.stack((X_time1, X_time2,X_time3,X_time4,X_time6,X_time9,X_time10,X_time11,X_time12,X_time13,X_time15,X_time16), axis=2)\n",
    "print(X_time.shape)\n",
    "# 定义非时间序列特征列\n",
    "non_time_features = [ 'MLT','Interpolated_Lstar', 'PitchAngle','MLAT']\n",
    "\n",
    "# 提取非时间序列数据\n",
    "X_non_time = combined_df[non_time_features].values  # 形状 (num_samples, 3)\n",
    "y = np.log10(combined_df['Flux'].values+10 ) # 形状 (num_samples,)\n",
    "\n",
    "# 如果是二分类任务，将其转换为二维数组\n",
    "y = y.reshape(-1, 1)  # 形状 (num_samples, 1)\n",
    "flux_error = combined_df['Flux_Error'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_time = MinMaxScaler()\n",
    "num_samples = X_time.shape[0]\n",
    "time_steps = 301  # 根据您的数据调整\n",
    "num_features = 12  # 您有16个时间序列特征\n",
    "X_time_reshaped = X_time.reshape(-1, num_features)  # (num_samples * time_steps, 16)\n",
    "X_time_scaled = scaler_time.fit_transform(X_time_reshaped)\n",
    "X_time = X_time_scaled.reshape(num_samples, time_steps, num_features)\n",
    "scaler_non_time = StandardScaler()\n",
    "X_non_time = scaler_non_time.fit_transform(X_non_time)\n",
    "scaler_target = MinMaxScaler()\n",
    "y_scaled = scaler_target.fit_transform(y)\n",
    "\n",
    "\n",
    "# 归一化 Flux_Error\n",
    "scaler_flux = MinMaxScaler()\n",
    "flux_error_scaled = scaler_flux.fit_transform(flux_error)  # 缩放到 [0, 1]\n",
    "\n",
    "# 反转权重（假设较高的 Flux_Error 表示较低的质量）\n",
    "flux_error_reversed = 1 - flux_error_scaled \n",
    "min_weight = 0.2\n",
    "flux_error_final = flux_error_reversed * (1 - min_weight) + min_weight  # 缩放到 [min_weight, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.3841023169859645 1.748151609272708\n",
      "-0.8501110903408742\n"
     ]
    }
   ],
   "source": [
    "print(X_non_time[:,1].min(), X_non_time[:,1].max())\n",
    "original_value = 3.1\n",
    "\n",
    "# 使用 scaler_non_time 转换原始值为标准化后的值\n",
    "scaled_value = scaler_non_time.transform([[0, original_value, 0, 0]])\n",
    "\n",
    "L_YZ=scaled_value[0,1]\n",
    "print(L_YZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_time_train, X_time_val, X_non_time_train, X_non_time_val, y_train, y_val, weight_train, weight_val = train_test_split(\n",
    "    X_time, X_non_time, y_scaled, flux_error_final, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入模型\n",
    "model = tf.keras.models.load_model('LSTM_M_2_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7517/7517 [==============================] - 22s 3ms/step\n",
      "测试集上的 RMSE: 0.22686856017490034 测试集上的 R2: 0.9530098308189923\n",
      "测试集上的 RMSE_10: 4077.023204855007\n",
      "预测效率 (PE): 0.9530098308189923\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val, X_non_time_val])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('m75_2_y_test_exp.txt', y_test_exp)\n",
    "np.savetxt('m75_2_y_pred_exp.txt', y_pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5856/5856 [==============================] - 16s 3ms/step\n",
      "测试集上的 RMSE: 0.18220225806176032 测试集上的 R2: 0.9635591940783145\n",
      "测试集上的 RMSE_10: 1013.4489692114227\n",
      "预测效率 (PE): 0.9635591940783145\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mask = X_non_time_val[:,1] < L_YZ\n",
    "X_non_time_val_out = X_non_time_val[~mask]\n",
    "X_time_val_out = X_time_val[~mask]\n",
    "y_val_out = y_val[~mask]\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val_out, X_non_time_val_out])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val_out)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661/1661 [==============================] - 5s 3ms/step\n",
      "测试集上的 RMSE: 0.3404293180511884 测试集上的 R2: 0.9330157536250687\n",
      "测试集上的 RMSE_10: 8462.1227877564\n",
      "预测效率 (PE): 0.9330157536250687\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mask = X_non_time_val[:,1] >= L_YZ\n",
    "X_non_time_val_out = X_non_time_val[~mask]\n",
    "X_time_val_out = X_time_val[~mask]\n",
    "y_val_out = y_val[~mask]\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val_out, X_non_time_val_out])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val_out)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
