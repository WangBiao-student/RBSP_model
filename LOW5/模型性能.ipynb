{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "# 完全忽略PerformanceWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df=pd.read_hdf('combined_df_train.h5', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Interpolated_Lstar           Flux\n",
      "0                  1.1     111.199249\n",
      "1                  1.2    3366.704406\n",
      "2                  1.3   18024.137790\n",
      "3                  1.4   40957.445793\n",
      "4                  1.5   66750.234802\n",
      "5                  1.6   86347.426551\n",
      "6                  1.7   98128.704941\n",
      "7                  1.8  103743.292059\n",
      "8                  1.9  107994.035752\n",
      "9                  2.0  109203.430753\n",
      "10                 2.1  112468.452791\n",
      "11                 2.2  114503.721870\n",
      "12                 2.3  114545.179311\n",
      "13                 2.4  109149.937884\n",
      "14                 2.5  103785.589245\n",
      "15                 2.6   94604.777103\n",
      "16                 2.7   85644.766897\n",
      "17                 2.8   73331.050594\n",
      "18                 2.9   61419.008508\n",
      "19                 3.0   49184.107454\n",
      "20                 3.1   38892.290173\n",
      "21                 3.2   30894.462217\n",
      "22                 3.3   24518.463683\n",
      "23                 3.4   19602.346793\n",
      "24                 3.5   16554.482211\n",
      "25                 3.6   14491.835225\n",
      "26                 3.7   13423.168062\n",
      "27                 3.8   13265.340362\n",
      "28                 3.9   13740.495231\n",
      "29                 4.0   14607.168497\n",
      "30                 4.1   15593.817344\n",
      "31                 4.2   15932.431574\n",
      "32                 4.3   17156.461473\n",
      "33                 4.4   18133.018291\n",
      "34                 4.5   18804.237252\n",
      "35                 4.6   19807.110699\n",
      "36                 4.7   21185.304876\n",
      "37                 4.8   21896.449647\n",
      "38                 4.9   22742.597601\n",
      "39                 5.0   23673.216501\n",
      "40                 5.1   24762.305710\n",
      "41                 5.2   24492.091481\n",
      "42                 5.3   24541.690011\n",
      "43                 5.4   24654.826796\n",
      "44                 5.5   25312.921516\n",
      "45                 5.6   24550.020687\n",
      "46                 5.7   22716.387402\n",
      "47                 5.8   20003.859443\n",
      "48                 5.9   18668.459657\n",
      "49                 6.0   16556.425572\n",
      "50                 6.1   16426.802756\n",
      "51                 6.2   14947.767952\n",
      "52                 6.3   15639.072395\n",
      "53                 6.4    8018.699080\n",
      "54                 6.5            NaN\n"
     ]
    }
   ],
   "source": [
    "combined_df=combined_df[combined_df['Kp_0h'] <30]\n",
    "flux_dict = {}\n",
    "for i in np.arange(1.1, 6.6, 0.1):\n",
    "    combined_df_i = combined_df[combined_df['Interpolated_Lstar'] > i]\n",
    "    combined_df_i = combined_df_i[combined_df_i['Interpolated_Lstar'] < i + 0.1]\n",
    "    #计算范围内的Flux均值\n",
    "    flux_mean = combined_df_i['Flux'].mean()\n",
    "    #将均值存入字典中\n",
    "    flux_dict[i] = flux_mean\n",
    "#将flux_dict保存为csv文件\n",
    "flux_df = pd.DataFrame(list(flux_dict.items()), columns=['Interpolated_Lstar', 'Flux'])\n",
    "print(flux_df)\n",
    "flux_df.to_csv('flux_L_80.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=300\n",
    "VX_time1 = [f'VX_{i}h' for i in range(0, time_steps + 1)]\n",
    "SYMH_time2 = [f'SYMH_{i}h' for i in range(0, time_steps + 1)]\n",
    "VX_IS1_time3 = [f'VX_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_time4 = [f'BZGSM_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_time5 = [f'TEMP_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_time6 = [f'PDYN_{i}h' for i in range(0, time_steps + 1)]\n",
    "Kp_time7 = [f'Kp_{i}h' for i in range(0, time_steps + 1)]\n",
    "Dst_time8 = [f'Dst_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_time9 = [f'F107_{i}h' for i in range(0, time_steps + 1)]\n",
    "AE_time10 = [f'AE_{i}h' for i in range(0, time_steps + 1)]\n",
    "AL_time11 = [f'AL_{i}h' for i in range(0, time_steps + 1)]\n",
    "AU_time12 = [f'AU_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_IS1_time13 = [f'BZGSM_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_IS1_time14 = [f'TEMP_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_IS1_time15 = [f'PDYN_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_IS1_time16 = [f'F107_IS1_{i}h' for i in range(0, time_steps + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012613, 151, 16)\n"
     ]
    }
   ],
   "source": [
    "X_time1 = combined_df[VX_time1].values  \n",
    "X_time2 = combined_df[SYMH_time2].values \n",
    "X_time3 = combined_df[VX_IS1_time3].values\n",
    "X_time4 = combined_df[BZGSM_time4].values\n",
    "X_time5 = combined_df[TEMP_time5].values\n",
    "X_time6 = combined_df[PDYN_time6].values\n",
    "X_time7 = combined_df[Kp_time7].values\n",
    "X_time8 = combined_df[Dst_time8].values\n",
    "X_time9 = combined_df[F107_time9].values\n",
    "X_time10 = combined_df[AE_time10].values\n",
    "X_time11 = combined_df[AL_time11].values\n",
    "X_time12 = combined_df[AU_time12].values\n",
    "X_time13 = combined_df[BZGSM_IS1_time13].values\n",
    "X_time14 = combined_df[TEMP_IS1_time14].values\n",
    "X_time15 = combined_df[PDYN_IS1_time15].values\n",
    "X_time16 = combined_df[F107_IS1_time16].values\n",
    "\n",
    "\n",
    "X_time = np.stack((X_time1, X_time2,X_time3,X_time4,X_time5,X_time6,X_time7,X_time8,X_time9,X_time10,X_time11,X_time12,X_time13,X_time14,X_time15,X_time16), axis=2)\n",
    "print(X_time.shape)\n",
    "# 定义非时间序列特征列\n",
    "non_time_features = [ 'MLT','Interpolated_Lstar', 'PitchAngle','MLAT']\n",
    "\n",
    "# 提取非时间序列数据\n",
    "X_non_time = combined_df[non_time_features].values  # 形状 (num_samples, 3)\n",
    "y = np.log10(combined_df['Flux'].values+10 ) # 形状 (num_samples,)\n",
    "\n",
    "# 如果是二分类任务，将其转换为二维数组\n",
    "y = y.reshape(-1, 1)  # 形状 (num_samples, 1)\n",
    "flux_error = combined_df['Flux_Error'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_time = MinMaxScaler()\n",
    "num_samples = X_time.shape[0]\n",
    "time_steps = 301  # 根据您的数据调整\n",
    "num_features = 16  # 您有16个时间序列特征\n",
    "X_time_reshaped = X_time.reshape(-1, num_features)  # (num_samples * time_steps, 16)\n",
    "X_time_scaled = scaler_time.fit_transform(X_time_reshaped)\n",
    "X_time = X_time_scaled.reshape(num_samples, time_steps, num_features)\n",
    "scaler_non_time = StandardScaler()\n",
    "X_non_time = scaler_non_time.fit_transform(X_non_time)\n",
    "scaler_target = MinMaxScaler()\n",
    "y_scaled = scaler_target.fit_transform(y)\n",
    "\n",
    "\n",
    "# 归一化 Flux_Error\n",
    "scaler_flux = MinMaxScaler()\n",
    "flux_error_scaled = scaler_flux.fit_transform(flux_error)  # 缩放到 [0, 1]\n",
    "\n",
    "# 反转权重（假设较高的 Flux_Error 表示较低的质量）\n",
    "flux_error_reversed = 1 - flux_error_scaled \n",
    "min_weight = 0.2\n",
    "flux_error_final = flux_error_reversed * (1 - min_weight) + min_weight  # 缩放到 [min_weight, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7334182744782385 1.8930510706085435\n",
      "-0.1371149128713236\n"
     ]
    }
   ],
   "source": [
    "print(X_non_time[:,2].min(), X_non_time[:,2].max())\n",
    "original_value = 3.7\n",
    "\n",
    "# 使用 scaler_non_time 转换原始值为标准化后的值\n",
    "scaled_value = scaler_non_time.transform([[0, original_value, 0, 0]])\n",
    "\n",
    "L_YZ=scaled_value[0,1]\n",
    "print(L_YZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_time_train, X_time_val, X_non_time_train, X_non_time_val, y_train, y_val, weight_train, weight_val = train_test_split(\n",
    "    X_time, X_non_time, y_scaled, flux_error_final, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入模型\n",
    "model = tf.keras.models.load_model('LSTM_HIGH_3_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329/6329 [==============================] - 19s 3ms/step\n",
      "测试集上的 RMSE: 0.33601703976757363 测试集上的 R2: 0.9138066087008725\n",
      "测试集上的 RMSE_10: 25101.332509680975\n",
      "预测效率 (PE): 0.9138066087008725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val, X_non_time_val])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('low_5_y_test_exp.txt', y_test_exp)\n",
    "np.savetxt('low_5_y_pred_exp.txt', y_pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3615/3615 [==============================] - 11s 3ms/step\n",
      "测试集上的 RMSE: 0.2926139966975526 测试集上的 R2: 0.9121384227251317\n",
      "测试集上的 RMSE_10: 23093.01664028757\n",
      "预测效率 (PE): 0.9121384227251317\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mask = X_non_time_val[:,1] < L_YZ\n",
    "X_non_time_val_out = X_non_time_val[~mask]\n",
    "X_time_val_out = X_time_val[~mask]\n",
    "y_val_out = y_val[~mask]\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val_out, X_non_time_val_out])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val_out)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2715/2715 [==============================] - 9s 3ms/step\n",
      "测试集上的 RMSE: 0.38631820924785726 测试集上的 R2: 0.9144830268228464\n",
      "测试集上的 RMSE_10: 27549.406610432758\n",
      "预测效率 (PE): 0.9144830268228464\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mask = X_non_time_val[:,1] >= L_YZ\n",
    "X_non_time_val_out = X_non_time_val[~mask]\n",
    "X_time_val_out = X_time_val[~mask]\n",
    "y_val_out = y_val[~mask]\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val_out, X_non_time_val_out])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val_out)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
