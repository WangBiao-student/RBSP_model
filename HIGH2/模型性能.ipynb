{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "# 完全忽略PerformanceWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df=pd.read_hdf('combined_df_train.h5', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df=combined_df[combined_df['Kp_0h'] <30]\n",
    "# flux_dict = {}\n",
    "# for i in np.arange(1.1, 6.6, 0.1):\n",
    "#     combined_df_i = combined_df[combined_df['Interpolated_Lstar'] > i]\n",
    "#     combined_df_i = combined_df_i[combined_df_i['Interpolated_Lstar'] < i + 0.1]\n",
    "#     #计算范围内的Flux均值\n",
    "#     flux_mean = combined_df_i['Flux'].mean()\n",
    "#     #将均值存入字典中\n",
    "#     flux_dict[i] = flux_mean\n",
    "# #将flux_dict保存为csv文件\n",
    "# flux_df = pd.DataFrame(list(flux_dict.items()), columns=['Interpolated_Lstar', 'Flux'])\n",
    "# print(flux_df)\n",
    "# flux_df.to_csv('flux_L_1728.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=300\n",
    "VX_time1 = [f'VX_{i}h' for i in range(0, time_steps + 1)]\n",
    "SYMH_time2 = [f'SYMH_{i}h' for i in range(0, time_steps + 1)]\n",
    "VX_IS1_time3 = [f'VX_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_time4 = [f'BZGSM_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_time5 = [f'TEMP_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_time6 = [f'PDYN_{i}h' for i in range(0, time_steps + 1)]\n",
    "Kp_time7 = [f'Kp_{i}h' for i in range(0, time_steps + 1)]\n",
    "Dst_time8 = [f'Dst_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_time9 = [f'F107_{i}h' for i in range(0, time_steps + 1)]\n",
    "AE_time10 = [f'AE_{i}h' for i in range(0, time_steps + 1)]\n",
    "AL_time11 = [f'AL_{i}h' for i in range(0, time_steps + 1)]\n",
    "AU_time12 = [f'AU_{i}h' for i in range(0, time_steps + 1)]\n",
    "BZGSM_IS1_time13 = [f'BZGSM_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "TEMP_IS1_time14 = [f'TEMP_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "PDYN_IS1_time15 = [f'PDYN_IS1_{i}h' for i in range(0, time_steps + 1)]\n",
    "F107_IS1_time16 = [f'F107_IS1_{i}h' for i in range(0, time_steps + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467341, 151, 12)\n"
     ]
    }
   ],
   "source": [
    "X_time1 = combined_df[VX_time1].values  \n",
    "X_time2 = combined_df[SYMH_time2].values \n",
    "X_time3 = combined_df[VX_IS1_time3].values\n",
    "X_time4 = combined_df[BZGSM_time4].values\n",
    "# X_time5 = combined_df[TEMP_time5].values\n",
    "X_time6 = combined_df[PDYN_time6].values\n",
    "# X_time7 = combined_df[Kp_time7].values\n",
    "# X_time8 = combined_df[Dst_time8].values\n",
    "X_time9 = combined_df[F107_time9].values\n",
    "X_time10 = combined_df[AE_time10].values\n",
    "X_time11 = combined_df[AL_time11].values\n",
    "X_time12 = combined_df[AU_time12].values\n",
    "X_time13 = combined_df[BZGSM_IS1_time13].values\n",
    "# X_time14 = combined_df[TEMP_IS1_time14].values\n",
    "X_time15 = combined_df[PDYN_IS1_time15].values\n",
    "X_time16 = combined_df[F107_IS1_time16].values\n",
    "\n",
    "\n",
    "X_time = np.stack((X_time1, X_time2,X_time3,X_time4,X_time6,X_time9,X_time10,X_time11,X_time12,X_time13,X_time15,X_time16), axis=2)\n",
    "print(X_time.shape)\n",
    "# 定义非时间序列特征列\n",
    "non_time_features = [ 'MLT','Interpolated_Lstar', 'PitchAngle','MLAT']\n",
    "\n",
    "# 提取非时间序列数据\n",
    "X_non_time = combined_df[non_time_features].values  # 形状 (num_samples, 3)\n",
    "y = np.log10(combined_df['Flux'].values+0.5 ) # 形状 (num_samples,)\n",
    "\n",
    "# 如果是二分类任务，将其转换为二维数组\n",
    "y = y.reshape(-1, 1)  # 形状 (num_samples, 1)\n",
    "flux_error = combined_df['Flux_Error'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_time = MinMaxScaler()\n",
    "num_samples = X_time.shape[0]\n",
    "time_steps = 301  # 根据您的数据调整\n",
    "num_features = 12  # 您有16个时间序列特征\n",
    "X_time_reshaped = X_time.reshape(-1, num_features)  # (num_samples * time_steps, 16)\n",
    "X_time_scaled = scaler_time.fit_transform(X_time_reshaped)\n",
    "X_time = X_time_scaled.reshape(num_samples, time_steps, num_features)\n",
    "scaler_non_time = StandardScaler()\n",
    "X_non_time = scaler_non_time.fit_transform(X_non_time)\n",
    "scaler_target = MinMaxScaler()\n",
    "y_scaled = scaler_target.fit_transform(y)\n",
    "\n",
    "\n",
    "# 归一化 Flux_Error\n",
    "scaler_flux = MinMaxScaler()\n",
    "flux_error_scaled = scaler_flux.fit_transform(flux_error)  # 缩放到 [0, 1]\n",
    "\n",
    "# 反转权重（假设较高的 Flux_Error 表示较低的质量）\n",
    "flux_error_reversed = 1 - flux_error_scaled \n",
    "min_weight = 0.2\n",
    "flux_error_final = flux_error_reversed * (1 - min_weight) + min_weight  # 缩放到 [min_weight, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4257829267435405 1.815085707075146\n",
      "-3.285345115743755\n"
     ]
    }
   ],
   "source": [
    "print(X_non_time[:,1].min(), X_non_time[:,1].max())\n",
    "original_value = 2.6\n",
    "\n",
    "# 使用 scaler_non_time 转换原始值为标准化后的值\n",
    "scaled_value = scaler_non_time.transform([[0, original_value, 0,0]])\n",
    "\n",
    "L_YZ=scaled_value[0,1]\n",
    "print(L_YZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_time_train, X_time_val, X_non_time_train, X_non_time_val, y_train, y_val, weight_train, weight_val = train_test_split(\n",
    "    X_time, X_non_time, y_scaled, flux_error_final, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入模型\n",
    "model = tf.keras.models.load_model('LSTM_H_2_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4586/4586 [==============================] - 14s 3ms/step\n",
      "测试集上的 RMSE: 0.18930574700548314 测试集上的 R2: 0.9683614598797141\n",
      "测试集上的 RMSE_10: 138.76706938022815\n",
      "预测效率 (PE): 0.9683614598797141\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mask = X_non_time_val[:,1] < L_YZ\n",
    "X_non_time_val_out = X_non_time_val[~mask]\n",
    "X_time_val_out = X_time_val[~mask]\n",
    "y_val_out = y_val[~mask]\n",
    "\n",
    "y_pred_scaled = model.predict([X_time_val_out, X_non_time_val_out])\n",
    "\n",
    "# 反缩放预测结果\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_test_subset = scaler_target.inverse_transform(y_val_out)\n",
    "# 生成布尔掩码\n",
    "\n",
    "\n",
    "y_test_exp = y_test_subset.flatten()\n",
    "y_pred_exp = y_pred.flatten()\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))\n",
    "r2 = r2_score(y_test_subset, y_pred)\n",
    "print(f'测试集上的 RMSE: {rmse}',f'测试集上的 R2: {r2}')\n",
    "\n",
    "y_test_10 = 10**y_test_exp\n",
    "y_pred_10 = 10**y_pred_exp\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test_10, y_pred_10)) \n",
    "print(f'测试集上的 RMSE_10: {rmse_10}')\n",
    "\n",
    "# 计算PE\n",
    "observed_values = y_test_exp  # 真实值\n",
    "predicted_values = y_pred_exp  # 预测值\n",
    "mean_observed = np.mean(observed_values)  # 真实值的均值\n",
    "\n",
    "# 计算PE\n",
    "numerator = np.sum((observed_values - predicted_values) ** 2)\n",
    "denominator = np.sum((observed_values - mean_observed) ** 2)\n",
    "\n",
    "pe = 1 - (numerator / denominator)\n",
    "\n",
    "print(f'预测效率 (PE): {pe}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('high_2_y_test_exp.txt', y_test_exp)\n",
    "np.savetxt('high_2_y_pred_exp.txt', y_pred_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
